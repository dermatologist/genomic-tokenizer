from genomic_tokenizer import GenomicTokenizer

fasta = """
AGGCGTACCCGCCCCTGGGGACGTCATTGGTGGCGGAGGCAATGGCCGGCAACCAGCTGTAAGCGAGGTA
GGCTCACTCGGGCGCGGAGGGTGCGGGTGAGAAAGGGAACGATTTGCTAGGAGTGTATGCGCCCGTGCTA
GGGCTCCCAGGAATTCTTACAAGCGTAGACAGCCTAGCAATCAGCCCTGTGAAGTGGGGTTCAGGGCAGA
"""
model_max_length = 2048
tokenizer = GenomicTokenizer(model_max_length)
tokens = tokenizer(fasta)
print(tokens)
